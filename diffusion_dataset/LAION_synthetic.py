# Synthetic dataset generated by InstanceDiffusion pipeline on LAION

import os
import numpy as np
import torch
import json
import cv2
from tqdm import tqdm
from .dataset_utils import BoundingBoxAndMaskAugmentation, bounding_box_to_mask

def rename_duplicated_label_with_index(labels):
    for i in range(len(labels)):
        if labels.count(labels[i]) > 1:
            labels[i] = labels[i] + f'_{labels[:i].count(labels[i])}'
    return labels

class LAIONSyntheticDataset(torch.utils.data.Dataset):
    def __init__(
        self,
        root, #path for images
        synthetic_data_dir=None, #path for synthetic data
        force_regenerate_meta=False,
        meta_name='meta',
        image_size=512,
        max_num_images=None,
        max_gt_per_img=20,
        validation=False,
    ):
        self.root = root
        self.image_size = image_size
        self.max_num_images = max_num_images
        if not meta_name.endswith('.json'):
            meta_name += '.json'
        self.json_path = os.path.join(root, meta_name)
        self.max_gt_per_img = max_gt_per_img

        self.transform = BoundingBoxAndMaskAugmentation(image_size)
        self.load_dataset(synthetic_data_dir, force_regenerate_meta)
        self.synthetic_data_dir = synthetic_data_dir

        if validation:
            self.data = self.data[:1000]
        if max_num_images is not None:
            self.data = self.data[:max_num_images]

        print('INFO: total images in dataset:', len(self.data))

    def load_dataset(self, synthetic_data_dir=None, force_regenerate_meta=False):
        if os.path.exists(self.json_path) and not force_regenerate_meta:
            with open(self.json_path, 'r') as f:
                self.data = json.load(f)
        else:
            print('Generating meta.json for LAION...')
            assert synthetic_data_dir is not None, 'synthetic_data_dir must be provided for LAIONSyntheticDataset when meta.json does not exist'

            self.data = []
            for parent_dir, _, _ in tqdm(os.walk(synthetic_data_dir)):
                for entry in os.scandir(parent_dir):
                    if entry.is_file() and entry.name.endswith('.json'):
                        json_path = entry.path
                        # named after xxxx/label_[id number].json
                        image_id = json_path.split('/')[-1].split('.')[0].split('_')[-1]
                        if image_id.lstrip('0') == '':
                            image_id_int = 0
                        else:
                            image_id_int = int(image_id.lstrip('0')) # id number are padded with 0s, need to remove them, int(00xxx) is not allowed
                        parent_folder = image_id_int // 10000

                        image_path = os.path.join(
                            self.root, 
                            'laion400m-images',
                            f'{parent_folder:05d}', 
                            f'{image_id}.jpg'
                        )
                        if os.path.exists(image_path):
                            self.data.append((image_path, json_path))

            with open(self.json_path, 'w') as f:
                json.dump(self.data, f, indent=4)

    def __len__(self):
        return len(self.data)

    def remove_padded_border(self, image, bboxes, image_meta_path):
        with open(image_meta_path, 'r') as f:
            image_meta = json.load(f)
        original_width = image_meta['original_width']
        original_height = image_meta['original_height']
        if original_height == original_width:
            return image, bboxes

        current_width, current_height = image.shape[1], image.shape[0]
        if original_height > original_width:
            # pad_side = 'horizontal'
            pad_size = (original_height - original_width) / 2
            ratio = current_height / original_height
            pad_size = int(pad_size * ratio)
            image = image[:, pad_size:current_width-pad_size, :]
            bboxes = [
                [bbox[0]-pad_size, bbox[1], bbox[2]-pad_size, bbox[3]] for bbox in bboxes
            ]
        else:
            # pad_side = 'vertical'
            pad_size = (original_width - original_height) / 2
            ratio = current_width / original_width
            pad_size = int(pad_size * ratio)
            image = image[pad_size:current_height-pad_size, :, :]
            bboxes = [
                [bbox[0], bbox[1]-pad_size, bbox[2], bbox[3]-pad_size] for bbox in bboxes
            ]
        return image, bboxes


    def process_image(self, image, bboxes, labels):
        # random crop image to fit image_size, change mask and bbox accordingly
        # random select bboxes and labels here
        indices = list(range(len(labels)))
        image, bboxes, labels, masks, indices = self.transform(image, bboxes, labels, None, indices)
        shuffle_ids = torch.randperm(len(labels))[:self.max_gt_per_img]
        selected_bboxes = [bboxes[i] for i in shuffle_ids]
        selected_labels = [labels[i] for i in shuffle_ids]
        selected_labels = rename_duplicated_label_with_index(selected_labels)
        return image, selected_bboxes, selected_labels

    def get_data_of_index(self, idx):

        image_path, json_path = self.data[idx]
        image_path = os.path.join(
            self.root, 
            image_path.split('/')[-3], 
            image_path.split('/')[-2], 
            image_path.split('/')[-1]
        )
        json_path = os.path.join(
            self.synthetic_data_dir, json_path.split('/')[-2], json_path.split('/')[-1]
        )
        with open(json_path, 'r') as f:
            json_data = json.load(f)

        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        caption = json_data['caption']
        annos = json_data['annos']
        bboxes = []
        labels = []

        for anno in annos:
            # bbox is in xywh format
            label = anno['caption']
            x, y, w, h = anno['bbox']
            x1, y1, x2, y2 = x, y, x+w, y+h # this is the bbox coordinates on the original size image
            bboxes.append([x1, y1, x2, y2])
            labels.append(label)

        image_meta_path = image_path.replace('.jpg', '.json')
        image, bboxes = self.remove_padded_border(image, bboxes, image_meta_path)

        image, bboxes, labels = self.process_image(image, bboxes, labels)

        h, w = image.shape[:2]
        masks = []
        for bbox in bboxes:
            mask = bounding_box_to_mask(h, w, bbox)
            masks.append(mask)

        if len(masks) > 0:
            masks = np.stack(masks, axis=0)
            masks = (masks > 0.5).astype(np.float32)

        return {
            'image_path': image_path,
            'image': (image / 255.0).astype(np.float32).transpose(2, 0, 1),
            'caption': caption,
            'bboxes': np.array(bboxes).astype(np.int16),
            'masks': masks,
            'labels': labels,
        }

    def __getitem__(self, idx):
        try:
            sample = self.get_data_of_index(idx)
            if len(sample['labels']) == 0:
                return self.__getitem__((idx + 1) % len(self))
            return sample
        except Exception as e:
            print(e)
            return self.__getitem__((idx + 1) % len(self))

class LAIONCategorySyntheticDataset(LAIONSyntheticDataset):
    def get_data_of_index(self, idx):

        image_path, json_path = self.data[idx]
        image_path = os.path.join(
            self.root, 
            image_path.split('/')[-3], 
            image_path.split('/')[-2], 
            image_path.split('/')[-1]
        )
        json_path = os.path.join(
            self.synthetic_data_dir, json_path.split('/')[-2], json_path.split('/')[-1]
        )
        with open(json_path, 'r') as f:
            json_data = json.load(f)

        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        caption = json_data['caption']
        annos = json_data['annos']
        bboxes = []
        labels = []

        for anno in annos:
            # bbox is in xywh format
            label = anno['category_name'] # the only edit part is here, change from caption (object description) to category_name
            x, y, w, h = anno['bbox']
            x1, y1, x2, y2 = x, y, x+w, y+h # this is the bbox coordinates on the original size image
            bboxes.append([x1, y1, x2, y2])
            labels.append(label)

        image_meta_path = image_path.replace('.jpg', '.json')
        image, bboxes = self.remove_padded_border(image, bboxes, image_meta_path)

        image, bboxes, labels = self.process_image(image, bboxes, labels)

        h, w = image.shape[:2]
        masks = []
        for bbox in bboxes:
            mask = bounding_box_to_mask(h, w, bbox)
            masks.append(mask)

        if len(masks) > 0:
            masks = np.stack(masks, axis=0)
            masks = (masks > 0.5).astype(np.float32)

        return {
            'image_path': image_path,
            'image': (image / 255.0).astype(np.float32).transpose(2, 0, 1),
            'caption': caption,
            'bboxes': np.array(bboxes).astype(np.int16),
            'masks': masks,
            'labels': labels,
        }

class LAIONSyntheticResolutionCompatibleDataset(LAIONSyntheticDataset):
    '''
    For handle labels that created on 256 resolution but the image is 512 resolution
    '''
    def __init__(
        self, 
        *args,
        label_resolution=256,
        actual_resolution=512,
        **kwargs
    ):
        self.label_resolution = label_resolution
        self.actual_resolution = actual_resolution
        self.bbox_scale = actual_resolution / label_resolution
        super().__init__(*args, **kwargs)

    def get_data_of_index(self, idx):

        image_path, json_path = self.data[idx]
        image_path = os.path.join(
            self.root, image_path.split('/')[-2], image_path.split('/')[-1]
        )
        json_path = os.path.join(
            self.synthetic_data_dir, json_path.split('/')[-2], json_path.split('/')[-1]
        )
        with open(json_path, 'r') as f:
            json_data = json.load(f)

        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        caption = json_data['caption']
        annos = json_data['annos']
        bboxes = []
        labels = []

        for anno in annos:
            # bbox is in xywh format
            label = anno['caption']
            x, y, w, h = anno['bbox']
            x1, y1, x2, y2 = x, y, x+w, y+h # this is the bbox coordinates on the original size image
            x1, y1, x2, y2 = int(x1 * self.bbox_scale), int(y1 * self.bbox_scale), int(x2 * self.bbox_scale), int(y2 * self.bbox_scale)
            bboxes.append([x1, y1, x2, y2])
            labels.append(label)

        image_meta_path = image_path.replace('.jpg', '.json')
        image, bboxes = self.remove_padded_border(image, bboxes, image_meta_path)

        image, bboxes, labels = self.process_image(image, bboxes, labels)

        h, w = image.shape[:2]
        masks = []
        for bbox in bboxes:
            mask = bounding_box_to_mask(h, w, bbox)
            masks.append(mask)

        if len(masks) > 0:
            masks = np.stack(masks, axis=0)
            masks = (masks > 0.5).astype(np.float32)

        return {
            'image_path': image_path,
            'image': (image / 255.0).astype(np.float32).transpose(2, 0, 1),
            'caption': caption,
            'bboxes': np.array(bboxes).astype(np.int16),
            'masks': masks,
            'labels': labels,
        }

import albumentations as A
class EvaluateBoundingBoxProcess():
    def __init__(self, image_size):
        self.image_size = image_size
        self.transform = A.Compose([
            A.SmallestMaxSize(max_size=image_size),
            A.CenterCrop(height=image_size, width=image_size),
        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['indices', 'labels'], min_visibility=0.3))

    def __call__(self, image, bboxes, labels, masks, indices=None):
        h, w = image.shape[:2]
        bboxes_fix_out_of_border = []
        for box in bboxes:
            x1, y1, x2, y2 = box
            if x1 >= x2: 
                x2 = x1 + 1
                x1 = x1 - 1
            if y1 >= y2:
                y2 = y1 + 1
                y1 = y1 - 1
            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)
            bboxes_fix_out_of_border.append([x1, y1, x2, y2])
        bboxes = bboxes_fix_out_of_border
        transformed = self.transform(image=image, bboxes=bboxes, labels=labels, masks=masks, indices=indices)
        return transformed['image'], transformed['bboxes'], transformed['labels'], transformed['masks'], transformed['indices']

class LAIONSyntheticEvalDataset(LAIONSyntheticDataset):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # use a deterministic transform for evaluation
        self.transform = EvaluateBoundingBoxProcess(self.image_size)

    def process_image(self, image, bboxes, labels):
        # random crop image to fit image_size, change mask and bbox accordingly
        # random select bboxes and labels here
        indices = list(range(len(labels)))
        image, bboxes, labels, masks, indices = self.transform(image, bboxes, labels, None, indices)
        shuffle_ids = list(range(len(labels)))[:self.max_gt_per_img]
        selected_bboxes = [bboxes[i] for i in shuffle_ids]
        selected_labels = [labels[i] for i in shuffle_ids]
        selected_labels = rename_duplicated_label_with_index(selected_labels)
        return image, selected_bboxes, selected_labels